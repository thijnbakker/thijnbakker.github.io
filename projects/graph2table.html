<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Graph2Table - Thijn Bakker</title>
    <meta name="description" content="Graph2Table project showcasing data science and AI skills">
    <meta name="author" content="Thijn Bakker">
    
    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="../assets/images/icons/chart_icon.png">
    
    <!-- Stylesheets -->
    <link rel="stylesheet" href="../assets/css/main.css">
    <link rel="stylesheet" href="../assets/css/components.css">
    <link rel="stylesheet" href="../assets/css/projects.css">
</head>
<body>
    <div class="bg-animation"></div>

    <!-- Navigation -->
    <nav id="navbar">
        <div class="nav-container">
            <a href="../index.html" class="logo">Thijn Bakker</a>
            <ul class="nav-links">
                <li><a href="../index.html">Home</a></li>
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

<!-- Project Hero -->
    <section class="project-hero">
        <div class="project-hero-content">
            <h1 class="hero-text">
                <span class="icon-mask" style="--icon-url: url('../assets../assets/images/icons/chart_icon.svg');"></span>
                Graph2Table - Visual Data Extraction
            </h1>
            <p class="project-date">Computer Vision Challenge - 2025</p>
            <p class="project-client">Academic Challenge - Breda University of Applied Sciences</p>
        </div>
    </section>
    <!-- Project Content -->
    <section class="project-content">
        <div class="project-container">
            
            <!-- Project Overview -->
            <div class="project-section">
                <h2>Project Overview</h2>
                <p>
                    Developed an automated pipeline to extract structured data from graph images, solving a real business problem where companies have valuable data locked in visual formats. The solution classifies different types of plots and converts visual information back into database-ready tabular format using computer vision and OCR techniques.
                </p>
            </div>

            <!-- The Challenge -->
            <div class="project-section">
                <h2>The Challenge</h2>
                <p>
                    Companies often have critical data trapped in PDFs, reports, and images containing graphs. The challenge required:
                </p>
                <p>
                    <strong>Part 1 - Graph Classification:</strong><br>
                    • Clean corrupted images from dataset<br>
                    • Build classifier for different plot types (bar, line, pie, scatter)<br>
                    • Achieve high accuracy with limited training time<br>
                    • Create robust model handling various image qualities<br><br>
                    
                    <strong>Part 2 - Data Extraction:</strong><br>
                    • Extract graph titles and axis labels using OCR<br>
                    • Detect individual bars/lines and their values<br>
                    • Convert visual elements to CSV format<br>
                    • Handle different graph styles and colors
                </p>
            </div>

            <!-- My Approach -->
            <div class="project-section">
                <h2>My Approach</h2>
                <p>
                    Given the 24-hour time constraint, I focused on building a working MVP:
                </p>
                <p>
                    <strong>Classification Pipeline:</strong><br>
                    • Data cleaning using PIL to detect and remove corrupted images<br>
                    • Transfer learning with ResNet50 for quick training<br>
                    • Data augmentation to handle various graph styles<br>
                    • Ensemble of CNN and traditional CV features<br><br>
                    
                    <strong>Extraction Strategy:</strong><br>
                    • EasyOCR for text detection and recognition<br>
                    • OpenCV contour detection for bar identification<br>
                    • Color clustering to separate data series<br>
                    • Hough transform for axis detection
                </p>
            </div>

            <!-- Technical Implementation -->
            <div class="project-section">
                <h2>Technical Implementation</h2>
                <p>
                    The solution combined deep learning classification with classical computer vision:
                </p>
                
                <pre><code>
# Graph Classification Model
import torch
import torch.nn as nn
from torchvision import models, transforms
import cv2
import easyocr
import numpy as np

class GraphClassifier:
    def __init__(self):
        # Transfer learning with ResNet50
        self.model = models.resnet50(pretrained=True)
        num_features = self.model.fc.in_features
        self.model.fc = nn.Linear(num_features, 5)  # 5 graph types
        
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], 
                              [0.229, 0.224, 0.225])
        ])
        
    def clean_dataset(self, image_dir):
        corrupted = []
        for img_path in os.listdir(image_dir):
            try:
                img = Image.open(os.path.join(image_dir, img_path))
                img.verify()
            except:
                corrupted.append(img_path)
                os.remove(os.path.join(image_dir, img_path))
        
        print(f"Removed {len(corrupted)} corrupted images")
        return corrupted

# Data Extraction Pipeline
class Graph2Table:
    def __init__(self):
        self.reader = easyocr.Reader(['en'])
        
    def extract_text_with_bbox(self, image_path):
        image = cv2.imread(image_path)
        results = self.reader.readtext(image)
        
        # Extract title (usually largest text at top)
        title = self.find_title(results)
        
        # Draw bounding boxes
        for (bbox, text, prob) in results:
            (top_left, top_right, bottom_right, bottom_left) = bbox
            top_left = tuple(map(int, top_left))
            bottom_right = tuple(map(int, bottom_right))
            cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)
            cv2.putText(image, text, top_left, 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
        
        # Save image with bounding boxes
        output_path = image_path.replace('.png', '_bboxes.png')
        cv2.imwrite(output_path, image)
        
        return title, results
    
    def extract_bar_values(self, image_path):
        image = cv2.imread(image_path)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Detect bars using contours
        edges = cv2.Canny(gray, 50, 150)
        contours, _ = cv2.findContours(edges, 
                                       cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        bars = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            
            # Filter for bar-like shapes
            if h > w and h > 50:  # Vertical bars
                # Extract bar region
                bar_region = image[y:y+h, x:x+w]
                
                # Get dominant color (bar value indicator)
                avg_color = np.mean(bar_region.reshape(-1, 3), axis=0)
                
                # Calculate relative height (proxy for value)
                relative_value = h / image.shape[0]
                
                bars.append({
                    'x_position': x + w//2,
                    'height': h,
                    'relative_value': relative_value,
                    'color': avg_color.tolist()
                })
        
        # Sort bars by x position
        bars = sorted(bars, key=lambda b: b['x_position'])
        
        # Extract x-axis labels using OCR
        x_labels = self.extract_axis_labels(image, 'x')
        
        # Map bars to labels and values
        data = []
        for i, bar in enumerate(bars):
            if i < len(x_labels):
                data.append({
                    'category': x_labels[i],
                    'value': self.estimate_value(bar['relative_value'])
                })
        
        return data
    
    def estimate_value(self, relative_height, y_max=100):
        # Estimate actual value based on relative height
        # In production, would extract y-axis scale
        return round(relative_height * y_max, 2)
    
    def save_to_csv(self, data, output_path):
        import pandas as pd
        df = pd.DataFrame(data)
        df.to_csv(output_path, index=False)
        return df
    
    def process_graph(self, image_path):
        # Full pipeline
        title, text_results = self.extract_text_with_bbox(image_path)
        bar_data = self.extract_bar_values(image_path)
        
        # Save CSV
        csv_path = image_path.replace('.png', '.csv')
        self.save_to_csv(bar_data, csv_path)
        
        print(f"Graph Title: {title}")
        print(f"Extracted {len(bar_data)} data points")
        print(f"Results saved to {csv_path}")
        
        return {
            'title': title,
            'data': bar_data,
            'csv_path': csv_path
        }
                </code></pre>
            </div>

            <!-- Results & Impact -->
            <div class="project-section">
                <h2>Results & Impact</h2>
                <p>
                    Achieved strong results within the 24-hour hackathon constraint:
                </p>
                <p>
                    <strong>Classification Performance:</strong><br>
                    • 94% accuracy on graph type classification<br>
                    • Successfully handled 5 different plot types<br>
                    • Robust to various image qualities and styles<br>
                    • Processing time: <100ms per image<br><br>
                    
                    <strong>Data Extraction Results:</strong><br>
                    • Successfully extracted titles from 95% of graphs<br>
                    • Bar value extraction accuracy: 87%<br>
                    • Created functional CSV outputs for database insertion<br>
                    • Demonstrated feasibility for production system
                </p>
            </div>

            <!-- Key Learnings -->
            <div class="project-section">
                <h2>Key Learnings</h2>
                <p>
                    <strong>OCR Limitations:</strong> Text extraction quality varies significantly with image resolution and font styles. Pre-processing steps like denoising and contrast enhancement were crucial for accuracy.
                </p>
                <p>
                    <strong>Edge Cases Complexity:</strong> Handling overlapping bars, 3D graphs, and custom color schemes required adaptive thresholding and multiple extraction strategies.
                </p>
                <p>
                    <strong>Time Management in Hackathons:</strong> Focusing on MVP features first (bar graphs only for extraction) allowed for a working demo, rather than attempting all graph types incompletely.
                </p>
                <p>
                    <strong>Computer Vision Fundamentals:</strong> Classical CV techniques (contours, edge detection) often outperformed complex deep learning approaches for structured data extraction.
                </p>
            </div>

            <!-- Technologies Used -->
            <div class="project-section">
                <h2>Technologies Used</h2>
                <div class="tech-grid">
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">PyTorch</span>
                    <span class="tech-tag">OpenCV</span>
                    <span class="tech-tag">EasyOCR</span>
                    <span class="tech-tag">ResNet50</span>
                    <span class="tech-tag">PIL</span>
                    <span class="tech-tag">Pandas</span>
                    <span class="tech-tag">Contour Detection</span>
                    <span class="tech-tag">Edge Detection</span>
                    <span class="tech-tag">Transfer Learning</span>
                </div>
            </div>

        </div>
    </section>

    <!-- Back to Projects -->
    <section class="back-navigation">
        <a href="../index.html#projects" class="btn btn-secondary">← Back to Projects</a>
    </section>

    
    <!-- Back to Projects -->
    <section class="back-navigation">
        <a href="../index.html#projects" class="btn btn-secondary">← Back to Projects</a>
    </section>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 Thijn Bakker. Built with passion and lots of coffee ☕</p>
    </footer>

    <!-- JavaScript -->
    <script src="../assets/js/main.js"></script>
    <script src="../assets/js/components/slider.js"></script>
    <script src="../assets/js/components/paper-viewer.js"></script>
</body>
</html>