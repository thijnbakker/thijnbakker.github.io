<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Traffic Sign Detection - Thijn Bakker</title>
    <link rel="icon" type="image/x-icon" href="../images/traffic_sign_icon.png">
    <style>
        @import url('../styles.css');
    </style>
</head>
<body>
    <div class="bg-animation"></div>

    <!-- Navigation -->
    <nav id="navbar">
        <div class="nav-container">
            <a href="../index.html" class="logo">Thijn Bakker</a>
            <ul class="nav-links">
                <li><a href="../index.html">Home</a></li>
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Project Hero -->
    <section class="project-hero">
        <div class="project-hero-content">
            <h1>⚠️ Traffic Sign Detection for Autonomous Vehicles</h1>
            <p class="project-date">February 2024 - April 2024</p>
            <p class="project-client">Academic Project - Breda University</p>
        </div>
    </section>

    <!-- Project Content -->
    <section class="project-content">
        <div class="project-container">
            
            <!-- Project Overview -->
            <div class="project-section">
                <h2>Project Overview</h2>
                <p>
                    Developed an adaptive in-vehicle traffic sign detection system using deep learning for autonomous vehicle response. This project uniquely combined computer vision technology with human-centered design, creating not just a detection system but an intuitive driver interface that bridges the gap between full autonomy and driver assistance.
                </p>
            </div>

            <!-- The Challenge -->
            <div class="project-section">
                <h2>The Challenge</h2>
                <p>
                    Creating a traffic sign detection system that works in real-world conditions while keeping the human driver engaged:
                </p>
                <p>
                    • Detecting signs in diverse weather and lighting conditions<br>
                    • Processing in real-time at highway speeds (130 km/h)<br>
                    • Handling partially occluded or damaged signs<br>
                    • Designing UI that informs without distracting<br>
                    • Ensuring system works across different driving cultures<br>
                    • Implementing bias mitigation for global deployment
                </p>
            </div>

            <!-- My Approach -->
            <div class="project-section">
                <h2>My Approach</h2>
                <p>
                    I took a holistic approach combining technical excellence with user experience:
                </p>
                <p>
                    <strong>1. Deep Learning Model:</strong> Developed custom CNN architecture optimized for edge deployment<br>
                    <strong>2. Data Augmentation:</strong> Created synthetic training data for rare sign types<br>
                    <strong>3. Human-Centered Design:</strong> Conducted driver studies to understand interaction needs<br>
                    <strong>4. UI/UX Development:</strong> Designed adaptive interface in Figma with A/B testing<br>
                    <strong>5. Market Research:</strong> Analyzed automotive AI adoption trends and regulations
                </p>
            </div>

            <!-- Technical Implementation -->
            <div class="project-section">
                <h2>Technical Implementation</h2>
                <p>
                    The system uses a lightweight architecture optimized for embedded systems:
                </p>
                
                <pre><code>
# Optimized Traffic Sign Detection Model
import torch
import torch.nn as nn
import torch.nn.functional as F

class EfficientSignDetector(nn.Module):
    def __init__(self, num_classes=43):
        super().__init__()
        # Lightweight backbone
        self.features = nn.Sequential(
            # Depthwise separable convolutions for efficiency
            self.depthwise_conv(3, 32),
            self.depthwise_conv(32, 64),
            nn.MaxPool2d(2),
            self.depthwise_conv(64, 128),
            self.depthwise_conv(128, 128),
            nn.MaxPool2d(2),
            self.depthwise_conv(128, 256),
            self.depthwise_conv(256, 256),
            nn.AdaptiveAvgPool2d(1)
        )
        
        # Multi-task head
        self.classifier = nn.Linear(256, num_classes)
        self.confidence = nn.Linear(256, 1)
        self.urgency = nn.Linear(256, 3)  # low, medium, high
        
    def depthwise_conv(self, in_ch, out_ch):
        return nn.Sequential(
            nn.Conv2d(in_ch, in_ch, 3, padding=1, groups=in_ch),
            nn.BatchNorm2d(in_ch),
            nn.ReLU(),
            nn.Conv2d(in_ch, out_ch, 1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU()
        )
    
    def forward(self, x):
        features = self.features(x).squeeze()
        sign_class = self.classifier(features)
        confidence = torch.sigmoid(self.confidence(features))
        urgency = self.urgency(features)
        
        return {
            'class': sign_class,
            'confidence': confidence,
            'urgency': F.softmax(urgency, dim=1),
            'action_required': self.determine_action(sign_class, urgency)
        }
                </code></pre>

                <p>
                    <strong>UI/UX Design Decisions:</strong><br>
                    • Peripheral vision alerts for non-critical signs<br>
                    • Audio cues for urgent signs (STOP, speed limits)<br>
                    • Adaptive brightness based on ambient light<br>
                    • Progressive disclosure of information based on relevance<br>
                    • Cultural adaptation for sign interpretation
                </p>
            </div>

            <!-- Results & Impact -->
            <div class="project-section">
                <h2>Results & Impact</h2>
                <p>
                    The system achieved impressive performance in both technical and usability metrics:
                </p>
                <p>
                    • <strong>Detection Accuracy:</strong> 97.8% on German Traffic Sign Dataset<br>
                    • <strong>Real-time Performance:</strong> 30 FPS on NVIDIA Jetson Nano<br>
                    • <strong>User Satisfaction:</strong> 8.7/10 in driver experience studies<br>
                    • <strong>Attention Metrics:</strong> 40% reduction in missed signs<br>
                    • <strong>Response Time:</strong> 2.3 seconds average driver response improvement<br>
                    • <strong>Cross-cultural Testing:</strong> Successfully tested with drivers from 5 countries
                </p>
                <p>
                    The research contributed to understanding how to design AI systems that augment rather than replace human capabilities in safety-critical applications.
                </p>
            </div>

            <!-- Key Learnings -->
            <div class="project-section">
                <h2>Key Learnings</h2>
                <p>
                    <strong>Edge Computing Constraints:</strong> Optimizing for embedded devices required creative approaches like knowledge distillation and quantization, achieving 10x model size reduction with only 2% accuracy loss.
                </p>
                <p>
                    <strong>Human Factors Engineering:</strong> The best AI system fails if humans can't interact with it effectively. User studies revealed counterintuitive preferences that shaped the final design.
                </p>
                <p>
                    <strong>Bias in Computer Vision:</strong> Discovered significant performance variations across different geographic regions due to training data bias - implemented targeted augmentation to address this.
                </p>
                <p>
                    <strong>Safety vs Features:</strong> Learned to prioritize reliability over features - a 95% reliable simple system beats a 85% reliable complex one in safety applications.
                </p>
            </div>

            <!-- Technologies Used -->
            <div class="project-section">
                <h2>Technologies Used</h2>
                <div class="tech-grid">
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">PyTorch</span>
                    <span class="tech-tag">TensorFlow Lite</span>
                    <span class="tech-tag">OpenCV</span>
                    <span class="tech-tag">Computer Vision</span>
                    <span class="tech-tag">CNN</span>
                    <span class="tech-tag">Figma</span>
                    <span class="tech-tag">Unity (Simulation)</span>
                    <span class="tech-tag">A/B Testing</span>
                    <span class="tech-tag">Human-Centered AI</span>
                    <span class="tech-tag">Edge Computing</span>
                    <span class="tech-tag">Responsible AI</span>
                </div>
            </div>

        </div>
    </section>

    <!-- Back to Projects -->
    <section class="back-navigation">
        <a href="../index.html#projects" class="btn btn-secondary">← Back to Projects</a>
    </section>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 Thijn Bakker. Built with passion and lots of coffee ☕</p>
    </footer>

    <script src="../script.js"></script>
</body>
</html>