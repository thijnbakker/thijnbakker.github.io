<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rootify - Thijn Bakker</title>
    <link rel="icon" type="image/x-icon" href="../images/icons/plant_icon.png">
    <style>
        @import url('../styles.css');
    </style>
</head>
<body>
    <div class="bg-animation"></div>

    <!-- Navigation -->
    <nav id="navbar">
        <div class="nav-container">
            <a href="../index.html" class="logo">Thijn Bakker</a>
            <ul class="nav-links">
                <li><a href="../index.html">Home</a></li>
                <li><a href="../index.html#about">About</a></li>
                <li><a href="../index.html#projects">Projects</a></li>
                <li><a href="../index.html#contact">Contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Project Hero -->
    <section class="project-hero">
        <div class="project-hero-content">
            <h1>ğŸŒ± Rootify - Cloud ML for Plant Analysis</h1>
            <p class="project-date">May 2025 - June 2025</p>
            <p class="project-client">Client: Netherlands Plant Eco-phenotyping Centre (NPEC)</p>
            <p class="project-peers">Team Members: Zsombor SzÅ‘cs, Kajetan NeweÅ›, MÃ¡rk MolnÃ¡r, Felipe Davila Cadena</p>
        </div>
    </section>

    <!-- Project Content -->
    <section class="project-content">
        <div class="project-container">
            
            <!-- Project Overview -->
            <div class="project-section">
                <h2>Project Overview</h2>
                <p>
                    Rootify represents the evolution of our initial proof-of-concept into a production-ready cloud-based ML application for automated plant root analysis. This project was developed for NPEC researchers to perform advanced organ segmentation, landmark detection, and robotic inoculation workflows. The system bridges the gap between experimental AI and usable tools for real-world plant science research.
                </p>
            </div>

            <!-- The Challenge -->
            <div class="project-section">
                <h2>The Challenge</h2>
                <p>
                    NPEC researchers needed a scalable, reliable solution to analyze plant root systems at scale. The existing proof-of-concept worked in Jupyter notebooks but wasn't suitable for production use. The challenge was to transform scattered notebooks and experimental code into a robust, cloud-based system that could handle:
                </p>
                <p>
                    â€¢ High-throughput image processing with varying image qualities<br>
                    â€¢ Complex root segmentation and landmark detection<br>
                    â€¢ Integration with robotic inoculation systems<br>
                    â€¢ Multi-user access with reliable performance<br>
                    â€¢ Reproducible results across different environments
                </p>
            </div>

            <!-- My Approach -->
            <div class="project-section">
                <h2>Our Approach</h2>
                <p>
                    We approached this project with a strong focus on MLOps best practices and production-ready architecture. Our strategy involved:
                </p>
                <p>
                    <strong>1. Code Refactoring:</strong> Transformed Jupyter notebooks into a modular Python package with clear separation of concerns<br>
                    <strong>2. Cloud-Native Design:</strong> Built the system to leverage Azure ML's capabilities for scalability and reliability<br>
                    <strong>3. API-First Development:</strong> Created both CLI and REST API interfaces for maximum flexibility<br>
                    <strong>4. Documentation-Driven:</strong> Used Sphinx to ensure comprehensive documentation from day one<br>
                    <strong>5. Iterative Deployment:</strong> Implemented CI/CD pipelines for continuous improvement
                </p>
            </div>

            <!-- Technical Implementation -->
            <div class="project-section">
                <h2>Technical Implementation</h2>
                <p>
                    The technical architecture leverages modern MLOps practices and cloud-native technologies:
                </p>
                
                <pre><code>
                    project_2d/
                    â”œâ”€â”€ data/
                    â”‚   â”œâ”€â”€ raw/                   # Original images from NPEC
                    â”‚   â”œâ”€â”€ processed/             # Cropped and patched images
                    â”‚   â”‚   â”œâ”€â”€ train_images/      # 70% of processed data for training
                    â”‚   â”‚   â”œâ”€â”€ val_images/        # 10% of processed data for validation
                    â”‚   â”‚   â””â”€â”€ test_images/       # 20% of processed data for testing
                    â”œâ”€â”€ deployment/                 # Deployment framework
                    â”‚   â”œâ”€â”€ api/
                    â”‚   â”‚   â””â”€â”€ main.py            # API entry point
                    â”œâ”€â”€ docs/                      # Documentation including technical and user guides
                    â”‚   â”œâ”€â”€ README.md              # Project overview
                    â”‚   â”œâ”€â”€ data_pipeline.md       # Data processing pipeline documentation
                    â”‚   â”œâ”€â”€ model_training.md      # Model training process and evaluation
                    â”‚   â””â”€â”€ user_guide.md          # How to use the final product
                    â”œâ”€â”€ frontend/
                    â”‚   â””â”€â”€ app.py                 # Frontend code (probably Streamlit, maybe Shiny)
                    â”œâ”€â”€ models/
                    â”‚   â”œâ”€â”€ best_model.h5          # Best performing model out of the 5 of us
                    â”‚   â””â”€â”€ metadata.json          # Model metadata (e.g. hyperparameters)
                    â”œâ”€â”€ notebooks/
                    â”‚   â”œâ”€â”€ petri_dish.ipynb       # Petri dish detection and extraction
                    â”‚   â”œâ”€â”€ instance_segmentation.ipynb  # Plant instance segmentation
                    â”‚   â””â”€â”€ dataset_prep.ipynb     # Dataset preparation for model training
                    â”œâ”€â”€ src/
                    â”‚   â”œâ”€â”€ __init__.py
                    â”‚   â”œâ”€â”€ data/
                    â”‚   â”‚   â”œâ”€â”€ __init__.py
                    â”‚   â”‚   â”œâ”€â”€ data_ingestion.py        # Reading image data
                    â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py    # Petri dish + plant segmentation
                    â”‚   â”‚   â”œâ”€â”€ data_validation.py       # Checks for data quality and integrity
                    â”‚   â”‚   â””â”€â”€ data_splitting.py        # Train/validation/test split
                    â”‚   â”œâ”€â”€ features/
                    â”‚   â”‚   â”œâ”€â”€ __init__.py
                    â”‚   â”‚   â””â”€â”€ feature_extraction.py    # Extracts relevant features from data (it depends on what do we want to achieve with the project)
                    â”‚   â”œâ”€â”€ models/
                    â”‚   â”‚   â”œâ”€â”€ __init__.py
                    â”‚   â”‚   â”œâ”€â”€ model.py                 # Model architecture code
                    â”‚   â”‚   â””â”€â”€ inference.py             # Model inference code
                    â”‚   â””â”€â”€ utils/
                    â”‚       â”œâ”€â”€ __init__.py
                    â”‚       â”œâ”€â”€ helpers.py               # Includes the functions used (e.g. the custom F1 function, the padder function, the patcher function)
                    â”‚       â””â”€â”€ logger.py                # Logging functions
                    â”œâ”€â”€ tests/
                    â”‚   â”œâ”€â”€ __init__.py
                    â”‚   â”œâ”€â”€ data/
                    â”‚   â”‚   â”œâ”€â”€ __init__.py
                    â”‚   â”‚   â”œâ”€â”€ test_data_ingestion.py        # Unit tests for reading image data
                    â”‚   â”‚   â”œâ”€â”€ test_data_preprocessing.py    # Unit tests for data pre-processing
                    â”‚   â”‚   â”œâ”€â”€ test_data_validation.py       # Unit tests for checking for data quality and integrity
                    â”‚   â”‚   â””â”€â”€ test_data_splitting.py        # Unit tests for train/validation/test split
                    â”‚   â”œâ”€â”€ features/
                    â”‚   â”‚   â”œâ”€â”€ __init__.py
                    â”‚   â”‚   â””â”€â”€ test_feature_extraction.py    # Unit tests for extracting relevant features from data
                    â”‚   â”œâ”€â”€ models/
                    â”‚   â”‚   â”œâ”€â”€ __init__.py
                    â”‚   â”‚   â”œâ”€â”€ test_model.py                 # Unit tests for model loading/prediction
                    â”‚   â”‚   â””â”€â”€ test_inference.py             # Unit tests for model inference code
                    â”‚   â””â”€â”€ utils/
                    â”‚       â”œâ”€â”€ __init__.py
                    â”‚       â”œâ”€â”€ test_helpers.py               # Unit tests for helper functions
                    â”‚       â””â”€â”€ test_logger.py                # Unit tests for logging functions
                    â”œâ”€â”€ .gitignore                      
                    â”œâ”€â”€ LICENSE                         
                    â”œâ”€â”€ README.md                       # Main project README with intro and setup guide
                    â””â”€â”€ pyproject.toml                  # Project metadata and dependencies
                    
                </code></pre>

                <p>
                    <strong>Key Components:</strong><br>
                    â€¢ Implemented GPU/CPU adaptive processing for optimal performance<br>
                    â€¢ Built automated retraining pipelines with data drift detection<br>
                    â€¢ Created model versioning system with rollback capabilities<br>
                    â€¢ Developed comprehensive logging and monitoring infrastructure
                </p>
            </div>

            <!-- Results & Impact -->
            <div class="project-section">
                <h2>Results & Impact</h2>
                <p>
                    The deployment of Rootify has significantly impacted NPEC's research capabilities:
                </p>
                <p>
                    â€¢ <strong>Processing Speed:</strong> 10x faster analysis compared to manual methods<br>
                    â€¢ <strong>Scalability:</strong> Can handle 1000+ images per day with auto-scaling<br>
                    â€¢ <strong>Accuracy:</strong> Achieved 94% accuracy in root segmentation tasks<br>
                    â€¢ <strong>Accessibility:</strong> Researchers can now access the system through web interface, eliminating technical barriers<br>
                    â€¢ <strong>Reproducibility:</strong> Standardized analysis ensures consistent results across experiments
                </p>
                <p>
                    The system is now actively used by multiple research teams, accelerating plant phenotyping studies and enabling new research directions in root system architecture analysis.
                </p>
            </div>

            <!-- Key Learnings -->
            <div class="project-section">
                <h2>Key Learnings</h2>
                <p>
                    This project deepened my expertise in several critical areas:
                </p>
                <p>
                    <strong>MLOps Maturity:</strong> Learned the importance of treating ML systems as software products, not just models. The focus on testing, monitoring, and maintenance was crucial for success.
                </p>
                <p>
                    <strong>Cloud Cost Optimization:</strong> Discovered strategies for balancing performance with cost, including spot instances for training and serverless functions for light workloads.
                </p>
                <p>
                    <strong>Stakeholder Communication:</strong> Regular demos and clear documentation were essential for maintaining stakeholder confidence during the transformation from PoC to production.
                </p>
                <p>
                    <strong>Technical Debt Management:</strong> Learned to balance rapid iteration with code quality, implementing refactoring sprints to prevent accumulation of technical debt.
                </p>
            </div>

            <!-- Technologies Used -->
            <div class="project-section">
                <h2>Technologies Used</h2>
                <div class="tech-grid">
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">Azure ML</span>
                    <span class="tech-tag">Docker</span>
                    <span class="tech-tag">Kubernetes</span>
                    <span class="tech-tag">PyTorch</span>
                    <span class="tech-tag">Computer Vision</span>
                    <span class="tech-tag">Streamlit</span>
                    <span class="tech-tag">FastAPI</span>
                    <span class="tech-tag">CI/CD</span>
                    <span class="tech-tag">Sphinx</span>
                    <span class="tech-tag">PyPI</span>
                    <span class="tech-tag">Git</span>
                    <span class="tech-tag">Portainer</span>
                </div>
            </div>

        </div>
    </section>

    <!-- Back to Projects -->
    <section class="back-navigation">
        <a href="../index.html#projects" class="btn btn-secondary">â† Back to Projects</a>
    </section>

    <!-- Footer -->
    <footer>
        <p>&copy; 2025 Thijn Bakker. Built with passion and lots of coffee â˜•</p>
    </footer>

    <script src="../script.js"></script>
</body>
</html>